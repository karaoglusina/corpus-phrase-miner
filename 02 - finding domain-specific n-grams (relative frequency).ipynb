{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook 2: Finding Domain-Specific Phrases by Comparing with General english\n",
        "\n",
        "Many meaningful phrases aren’t specific to the design session. \"Makes sense\" has high MI but appears everywhere and doesn't tell us anything about the context of the design session.  What matters here is **domain specificity**: phrases that are **proportionally more common** in the design session than in general English. In this notebook we compare **relative frequencies** between the design corpus and a general-English reference to find such phrases, quantify their **effect size** (log ratio), and assess **statistical significance** (log-likelihood ratio; G-test)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.Inputs & Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import unicodedata\n",
        "\n",
        "from src.ngram_extraction import extract_ngrams_from_corpus\n",
        "from src.text_utils import clean_text\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', 50)\n",
        "sns.set_context('talk')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional - Enable automatic reloading of modules when source code changes\n",
        "# This eliminates the need to restart the kernel when updating external .py files.\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load dataframes from previous notebook\n",
        "session_ngrams = pd.read_csv('outputs/session_ngrams_1.csv')\n",
        "session_turns = pd.read_csv('outputs/session_turns.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Building Reference Corpus and Extracting N-grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To provide general-language baselines for frequency and MI comparisons, several large English corpora can be used:   \n",
        "- C4 (Colossal Clean Crawled Corpus) \n",
        "  - cleaned web text corpus by AllenAI (HuggingFace: `allenai/c4`). Used here via a Kaggle subset: `almirneto/corpus-c4`.  \n",
        "  - very large, 300m+ lines. \n",
        "- Switchboard Corpus \n",
        "  - transcribed English telephone conversations, representing spoken dialogue patterns.  \n",
        "- OpenSubtitles \n",
        "  - English movie and TV subtitles, representing informal conversational language across diverse contexts.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Option 1: very large corpora\n",
        " \n",
        "You can place the CSV files of any of the above corpora into a folder and use `extract_counts_for_target_ngrams_from_csv_folder` function. This function can handle very large corpus sizes like `C4` by only counting the session ngrams and streaming the files rather than loading all of theminto RAM all at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.ngram_extraction import extract_counts_for_target_ngrams_from_csv_folder\n",
        "\n",
        "folder = \"/Users/skaraoglu/Documents/vis-analysis-designing_senthil/data/corpora\"\n",
        "targets = session_ngrams['ngram'].astype(str).tolist()\n",
        "\n",
        "reference_ngrams = extract_counts_for_target_ngrams_from_csv_folder(\n",
        "    folder_path=folder,\n",
        "    target_ngrams=targets,\n",
        "    text_column=\"text\",\n",
        "    chunksize=250_000,           # tune to RAM\n",
        "    remove_punctuation=True,\n",
        "    frequency_column=\"frequency_in_reference\"\n",
        ")\n",
        "\n",
        "# Uncomment to save the reference_ngrams dataframe to a CSV file\n",
        "# pd.to_csv('outputs/reference_ngrams.csv', index=False)\n",
        "\n",
        "# Uncomment to load the reference_ngrams dataframe from a CSV file\n",
        "# reference_ngrams = pd.read_csv('outputs/reference_ngrams.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Option 2: from single CSV\n",
        "If a very large corpora is not necessary, you can load a CSV file, create a dataframe and use `extract_ngrams_from_corpus`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import unicodedata \n",
        "\n",
        "# Load reference corpus (merged Switchboard + OpenSubtitles)\n",
        "reference_turns = pd.read_csv(\n",
        "    'data/switchboard_opensubtitles_merged.csv',\n",
        "    dtype={'text': 'string'},          # ensure consistent string type for text\n",
        "    usecols=['text'],                  # only the text column is needed\n",
        "    encoding='utf-8',                  # try utf-8 first; fallback to 'latin1' if needed\n",
        "    on_bad_lines='skip',               # skip ill-formed rows\n",
        "    low_memory=False                   # avoid dtype inference chunking\n",
        ")\n",
        "\n",
        "# Normalize Unicode in-place to mitigate ambiguous unicode characters\n",
        "reference_turns['text'] = reference_turns['text'].astype(str).map(lambda s: unicodedata.normalize('NFKC', s))\n",
        "reference_turns = clean_text(reference_turns)\n",
        "\n",
        "reference_ngrams = extract_ngrams_from_corpus(\n",
        "    reference_turns,\n",
        "    text_column='text',\n",
        "    n_gram_min=1, \n",
        "    n_gram_max=3,\n",
        "    preprocess=True,\n",
        "    remove_punctuation=True\n",
        ")\n",
        "\n",
        "reference_ngrams = reference_ngrams.rename(columns={'frequency':'frequency_in_reference'})\n",
        "reference_ngrams.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Finding session-only n-grams\n",
        "\n",
        "N-grams that appear **only** in the design session but not in the reference corpus may show us 'neologisms', newly formed phrases. Since we have all n-grams in both the reference corpus and the design session data, we can extract which of them are only used in the session.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# n-grams present in session_ngrams but absent from reference_ngrams\n",
        "session_only_ngrams = (\n",
        "    session_ngrams.merge(\n",
        "        reference_ngrams[['ngram','ngram_length']].drop_duplicates(),\n",
        "        on=['ngram','ngram_length'],\n",
        "        how='left',\n",
        "        indicator=True\n",
        "    )\n",
        "    .query('_merge == \"left_only\"')\n",
        "    .sort_values('frequency_in_session', ascending=False)\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "print(f\"Total n-grams in session_ngrams: {len(session_ngrams)}\")\n",
        "print(f\"Total n-grams unique to session (session_only_ngrams): {len(session_only_ngrams)}\")\n",
        "disqualified_ngrams = len(session_ngrams) - len(session_only_ngrams)\n",
        "print(f\"Number of n-grams present in reference_ngrams thus were not considered unique to the session: {disqualified_ngrams}\")\n",
        "session_only_ngrams.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.mi_visualization import create_parametric_ngram_scatter\n",
        "\n",
        "df = session_only_ngrams[\n",
        "    (session_only_ngrams['mi_in_session_z'] > 0) &\n",
        "    (session_only_ngrams['speaker_count'] > 1) &\n",
        "    (session_only_ngrams['frequency_in_session'] > 3) & (session_only_ngrams['frequency_in_session'] < 50) &  \n",
        "    (session_only_ngrams['ngram_length'] > 1)\n",
        "]\n",
        "\n",
        "import altair as alt\n",
        "\n",
        "chart = create_parametric_ngram_scatter(\n",
        "    df=df,\n",
        "    x_col='mi_in_session_z', x_mode='continuous', x_scale='linear', x_bin=False,\n",
        "    y_col='frequency_rank_within_length', y_mode='continuous', y_scale='linear', y_bin=False,\n",
        "    color_col='ngram_length', color_mode='categorical',\n",
        "    color_scheme='tableau10',  # or 'category20', etc.\n",
        "    opacity=0.8, \n",
        "    width=300, height=400\n",
        ")\n",
        "\n",
        "chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example session-only ngrams\n",
        "\n",
        "Design-only phrases might signal potential novelty but need further validation:\n",
        "\n",
        "- Coined terms: \"sexy commitment\", \"lifetime companion\", \"pockets of enjoyment\" \n",
        "- Technical jargon: \"co-creation session\"\n",
        "- Person names: \"Tiffany and Hans\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.mi_visualization import ngram_examples_grid\n",
        "\n",
        "df = session_only_ngrams[\n",
        "    (session_only_ngrams['mi_in_session_z'] > 0) &\n",
        "    (session_only_ngrams['speaker_count'] > 1) &\n",
        "    (session_only_ngrams['frequency_in_session'] > 3) &\n",
        "    (session_only_ngrams['ngram_length'] > 1)\n",
        "]\n",
        "\n",
        "table_df, fig = ngram_examples_grid(\n",
        "    df=df,\n",
        "    x_col='mi_in_session_z', x_mode='continuous', x_binning='linear', x_bins=6,\n",
        "    y_col='frequency_rank_within_length',   y_mode='continuous', y_binning='log', y_bins=10,\n",
        "    color_col='ngram_length', color_mode='categorical', color_scheme='tableau20b',    \n",
        "    examples_per_cell=6, wrap_width=22, figsize=(12, 16),\n",
        "    y_label='Frequency ranks of ngrams within same length (log bins)', tick_fontsize=12, label_fontsize=12, cell_text_fontsize=9,\n",
        "    x_label='Normalised MI (linear bins)', \n",
        "    cell_fill='#e9edf2', cell_fill_alpha=0.7\n",
        ")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.  Measuring the Domain Specificity by comparing session data and reference data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initially, we might think phrases unique to the design corpus are most interesting. However, this misses phrases that exist in everyday language but take on special significance in the context of the design session.  \n",
        "\n",
        "\n",
        "\n",
        "**Finding phrases that are used in the session significantly more frequent than the general english**:\n",
        "\n",
        "- Compare phrase frequencies between design and reference corpora  \n",
        "- Calculate effect sizes (how much more/less common in design)  \n",
        "- Apply log-likelihood ratio test for statistical significance  \n",
        "\n",
        "**Effect Size Formula**:\n",
        "\n",
        "$$\\text{Effect Size} = \\log_2 \\left( \\frac{f_{design}/N_{design}}{f_{reference}/N_{reference}} \\right)$$\n",
        "\n",
        "\n",
        "**Interpretation**\n",
        "- **Positive effect size** → overrepresented in **design**  \n",
        "- **Negative** → overrepresented in **reference** (generic)  \n",
        "- **Near zero** → proportionally similar\n",
        "\n",
        "\n",
        "**Expected Insights**: Phrases like \"opportunity areas\" will show high domain specificity, while common phrases like \"I think\" will not—even if they have high MI."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build comparison table on overlapping n-grams\n",
        "We’ll use design frequencies from `design_mi` and reference frequencies from extracted `reference_ngrams`. We align the two corpora on the **overlap set** of n-grams and bring in: \n",
        "- `frequency_in_session`, `frequency_in_reference`\n",
        "- Totals per length: `total_ngrams_in_session`, `total_ngrams_in_reference`\n",
        "- Derived **rates** and `effect_size_log_ratio`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build frequency_comparisonarison on overlapping n-grams using unified names\n",
        "Overlap = set(session_ngrams['ngram']) & set(reference_ngrams['ngram'])\n",
        "\n",
        "frequency_comparison = (\n",
        "    session_ngrams[session_ngrams['ngram'].isin(Overlap)][['ngram','ngram_length','frequency_in_session']]\n",
        "    .merge(\n",
        "        reference_ngrams[reference_ngrams['ngram'].isin(Overlap)][['ngram','ngram_length','frequency_in_reference']],\n",
        "        on=['ngram','ngram_length'], how='inner'\n",
        "    )\n",
        ")\n",
        "print(len(frequency_comparison))\n",
        "frequency_comparison.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compute totals per n-gram length and effect size (log2 ratio)\n",
        "- design_total_ngrams and reference_total_ngrams per `ngram_length`.\n",
        "- effect_size_log_ratio = log2( (fd/Nd + α) / (fr/Nr + α) ).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Totals by length\n",
        "Ns_by_len = session_ngrams.groupby('ngram_length')['frequency_in_session'].sum().to_dict()\n",
        "Nr_by_len = reference_ngrams.groupby('ngram_length')['frequency_in_reference'].sum().to_dict()\n",
        "\n",
        "frequency_comparison['total_ngrams_in_session'] = frequency_comparison['ngram_length'].map(Ns_by_len)\n",
        "frequency_comparison['total_ngrams_in_reference'] = frequency_comparison['ngram_length'].map(Nr_by_len)\n",
        "\n",
        "\n",
        "alpha = 0.5 # Add small constant to avoid division by zero`\n",
        "\n",
        "# Calculate relative frequencies in each corpus \n",
        "frequency_comparison['rate_in_session'] = (frequency_comparison['frequency_in_session'] + alpha) / (frequency_comparison['total_ngrams_in_session'] + 2*alpha)\n",
        "frequency_comparison['rate_in_reference'] = (frequency_comparison['frequency_in_reference'] + alpha) / (frequency_comparison['total_ngrams_in_reference'] + 2*alpha)\n",
        "# frequency_comparisonute log2 ratio: log2(freq_design / freq_reference) \n",
        "frequency_comparison['effect_size_log_ratio'] = np.log2(frequency_comparison['rate_in_session'] / frequency_comparison['rate_in_reference'])\n",
        "frequency_comparison[['ngram','ngram_length','frequency_in_session','frequency_in_reference','effect_size_log_ratio', 'rate_in_session']].head(10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing Statistical significance: Log-likelihood ratio (G-test)\n",
        "Effect size shows magnitude, but we also need statistical confidence. The log-likelihood ratio (G-test) tells us whether observed differences could be due to chance.\n",
        "\n",
        "We apply the standard G-test per phrase using a 2x2 table and mark significance (p < 0.05). Small p-values indicate reliable differences. This prevents over-interpreting noisy variations, especially for rare phrases.\n",
        "\n",
        "The test works by comparing observed frequencies with expected frequencies if there were no corpus preference:\n",
        "\n",
        "- **G > 3.84**: Significant difference (95% confidence)\n",
        "- **p < 0.05**: Less than 5% chance the difference is random\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.stats import chi2\n",
        "\n",
        "# Apply log-likelihood ratio test \n",
        "\n",
        "def log_likelihood_ratio(k1, n1, k2, n2, eps=1e-12):\n",
        "    p = (k1 + k2) / (n1 + n2)\n",
        "    p1 = k1 / n1\n",
        "    p2 = k2 / n2\n",
        "    def safe_log(x):\n",
        "        return np.log(max(x, eps))\n",
        "    ll = 2 * (\n",
        "        k1 * safe_log(p1 / p) + (n1 - k1) * safe_log((1 - p1) / (1 - p)) +\n",
        "        k2 * safe_log(p2 / p) + (n2 - k2) * safe_log((1 - p2) / (1 - p))\n",
        "    )\n",
        "    return ll\n",
        "\n",
        "frequency_comparison['G'] = frequency_comparison.apply(\n",
        "    lambda r: log_likelihood_ratio(\n",
        "        k1=int(r['frequency_in_session']), n1=int(r['total_ngrams_in_session']),\n",
        "        k2=int(r['frequency_in_reference']), n2=int(r['total_ngrams_in_reference'])\n",
        "    ), axis=1\n",
        ")\n",
        "# Calculate G statistic and p-values \n",
        "frequency_comparison['p_value'] = 1 - chi2.cdf(frequency_comparison['G'], df=1)\n",
        "\n",
        "# Mark significance threshold (typically p < 0.05)`\n",
        "frequency_comparison['significant'] = frequency_comparison['p_value'] < 0.05\n",
        "\n",
        "frequency_comparison[['ngram','effect_size_log_ratio','G','p_value','significant']].head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session_ngrams = session_ngrams.merge(\n",
        "    frequency_comparison.loc[:, ['ngram', 'effect_size_log_ratio', 'significant', 'rate_in_session']], \n",
        "    on='ngram', \n",
        "    how='left', \n",
        "    suffixes=('', '_frequency_comparison')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "session_ngrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Understanding the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization reveals:\n",
        "\n",
        "- High effect size + significant: Strong domain specificity\n",
        "- High effect size + not significant: Possibly interesting but unreliable\n",
        "- Near zero effect size: Common to both corpora\n",
        "\n",
        "\n",
        "This filtering dramatically reduces our candidate pool, removing everyday English expressions while preserving design-relevant language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.mi_visualization import create_parametric_ngram_scatter\n",
        "\n",
        "df = session_ngrams[\n",
        "    (session_ngrams['mi_in_session_z'] > 0) &\n",
        "    (session_ngrams['speaker_count'] > 1) &\n",
        "    (session_ngrams['frequency_in_session'] > 3) & (session_ngrams['frequency_in_session'] < 50) &  \n",
        "    (session_ngrams['ngram_length'] > 1)\n",
        "    \n",
        "]\n",
        "\n",
        "import altair as alt\n",
        "\n",
        "chart = create_parametric_ngram_scatter(\n",
        "    df=df,\n",
        "    x_col='effect_size_log_ratio', x_mode='continuous', x_scale='linear', x_bin=False,\n",
        "    y_col='frequency_rank_within_length', y_mode='continuous', y_scale='linear', y_bin=False,\n",
        "    color_col='significant', color_mode='categorical',\n",
        "    color_scheme='viridis',  # or 'category20', etc.\n",
        "    opacity=0.7, \n",
        "    width=300, height=400\n",
        ")\n",
        "\n",
        "\n",
        "chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Below we restrict to phrases that are both  overrepresented in design (`effect_size_log_ratio > 0`) and statistically significant (`significant == True`)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.mi_visualization import create_parametric_ngram_scatter\n",
        "\n",
        "\n",
        "df = session_ngrams[\n",
        "    (session_ngrams['mi_in_session_z'] > 0) &\n",
        "    (session_ngrams['speaker_count'] > 1) &\n",
        "    (session_ngrams['frequency_in_session'] > 3) & (session_ngrams['frequency_in_session'] < 100) &\n",
        "    (session_ngrams['frequency_rank_within_length'] > 100) &\n",
        "    (session_ngrams['ngram_length'] > 1)&\n",
        "    (session_ngrams['significant'] == True)\n",
        "    & (session_ngrams['effect_size_log_ratio'] > 0)\n",
        "    \n",
        "]\n",
        "\n",
        "import altair as alt\n",
        "\n",
        "chart = create_parametric_ngram_scatter(\n",
        "    df=df,\n",
        "    x_col='effect_size_log_ratio', x_mode='continuous', x_scale='linear', x_bin=False,\n",
        "    y_col='frequency_rank_within_length', y_mode='continuous', y_scale='linear', y_bin=False,\n",
        "    color_col='mi_in_session_z', color_mode='continuous',\n",
        "    color_scheme='reds',  # or 'category20', etc.\n",
        "    opacity=0.7, \n",
        "    width=300, height=400\n",
        ")\n",
        "\n",
        "chart"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example n-grams\n",
        "\n",
        "- **x (→ right)**: `effect_size_log_ratio` — higher values = **more overrepresented in design**; negatives = overrepresented in **reference**.  \n",
        "- **y (↑ up)**: `frequency_rank_within_length` (log-binned) — **less frequent** as you go up (rank 1 = most frequent within that length).  \n",
        "- **color**: `mi_in_session_z` (Reds) — **darker = more cohesive** (higher PMI z) in the design corpus.\n",
        "\n",
        "**How to read**\n",
        "- **Bottom-right**: overrepresented & relatively frequent → strong domain terms.  \n",
        "- **Top-right**: overrepresented but rare → specialized or emerging phrases (inspect).  \n",
        "- **Left side**: generic or everyday; more common in reference than design.  \n",
        "- **Color** helps prioritize **cohesive** phrases among the design-specific ones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.mi_visualization import ngram_examples_grid\n",
        "\n",
        "df = session_ngrams[\n",
        "    (session_ngrams['mi_in_session_z'] > 0.6) &\n",
        "    (session_ngrams['speaker_count'] > 1) &\n",
        "    (session_ngrams['frequency_in_session'] > 3) & (session_ngrams['frequency_in_session'] < 100) &\n",
        "    (session_ngrams['frequency_rank_within_length'] > 100) &\n",
        "    (session_ngrams['ngram_length'] > 1)&\n",
        "    (session_ngrams['significant'] == True)\n",
        "    & (session_ngrams['effect_size_log_ratio'] > 0)\n",
        "    \n",
        "]\n",
        "\n",
        "table_df, fig = ngram_examples_grid(\n",
        "    df=df,\n",
        "    x_col='effect_size_log_ratio', x_mode='continuous', x_binning='linear', x_bins=6,\n",
        "    y_col='frequency_rank_within_length',   y_mode='continuous', y_binning='log', y_bins=10,\n",
        "    color_col='mi_in_session_z', color_mode='continuous', color_scheme='Reds',\n",
        "    \n",
        "    examples_per_cell=6, wrap_width=20, figsize=(9, 17),\n",
        "    tick_fontsize=12, label_fontsize=14, cell_text_fontsize=9,\n",
        "    cell_fill='#e9edf2', cell_fill_alpha=0.7\n",
        ")\n",
        "plt.show()\n",
        "len(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Save\n",
        "We save the enriched `session_ngrams` with:\n",
        "- `effect_size_log_ratio`, `G`, `p_value`, `significant`\n",
        "- (and any Cohesion fields carried over from Notebook 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frequency_comparison.to_csv('outputs/frequency_comparison.csv', index=False)\n",
        "session_ngrams.to_csv('outputs/session_ngrams_2_effect_size.csv', index=False)\n",
        "reference_ngrams.to_csv('outputs/reference_ngrams.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "vis-analysis",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
